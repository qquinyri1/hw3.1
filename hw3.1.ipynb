{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(X, w):\n",
    "    return np.dot(X, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(X, y, w):\n",
    "    return np.square(h(X, w) - y).sum() / (2 * len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_w(X, y, w):\n",
    "    m = len(X)\n",
    "    return np.dot(X.T, (h(X, w) - y)) / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_step(w, grad_w, learning_rate=0.001):\n",
    "    w = w - learning_rate*grad_w\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent(X, y, w, num_iter=10000, learning_rate=0.001, epsilon=0.0000001):\n",
    "\n",
    "    loss = loss_function(X, y, w)\n",
    "    loss_history = [loss]\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        w_best = None\n",
    "        d_w = grad_w(X, y, w)\n",
    "        w = grad_step(w, d_w, learning_rate=learning_rate)\n",
    "\n",
    "        loss = loss_function(X, y, w)\n",
    "        if abs(loss - loss_history[-1]) < epsilon:\n",
    "            loss_history.append(loss)\n",
    "            w_best = d_w\n",
    "            break\n",
    "        \n",
    "        loss_history.append(loss)\n",
    "        \n",
    "    return w, w_best, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(data):\n",
    "    return (data - data.mean())/data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_df = pd.DataFrame()\n",
    "\n",
    "n_df[\"price\"] = normalization(df[\"price\"])\n",
    "n_df[\"area\"] = normalization(df[\"area\"])\n",
    "n_df[\"bathrooms\"] = normalization(df[\"bathrooms\"])\n",
    "n_df[\"bedrooms\"] = normalization(df[\"bedrooms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = n_df[['area', 'bathrooms', 'bedrooms']].values\n",
    "X = np.hstack((np.ones((X.shape[0], 1)) , X))\n",
    "y = n_df[\"price\"].values.reshape(-1, 1)\n",
    "\n",
    "n = X.shape[1]\n",
    "w = np.linspace(0, 0, n).reshape((n, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.46671666e-17 -6.74033514e-03 -4.72771123e-03  5.66844067e-03]\n",
      "0.25605342833253486\n"
     ]
    }
   ],
   "source": [
    "w, w_best, loss_history = grad_descent(X, y, w, 10000, learning_rate=0.001)\n",
    "loss_best = loss_history[-1]\n",
    "print(w_best.flatten())\n",
    "print(loss_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best analitical w:  [9.86731840e-17 4.39452085e-01 3.72344423e-01 1.60528660e-01]\n",
      "The best analitical loss function:  0.2559879006532141\n"
     ]
    }
   ],
   "source": [
    "a_w = np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)), X.T), y)\n",
    "a_loss = loss_function(X, y, a_w)\n",
    "print(a_w.flatten())\n",
    "print(a_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.2561} {0.256}\n"
     ]
    }
   ],
   "source": [
    "best_values_of_loss_function = loss_best\n",
    "best_analitical_loss_function = a_loss\n",
    "a = best_values_of_loss_function \n",
    "b = best_analitical_loss_function\n",
    "\n",
    "if a > b:\n",
    "    print({best_values_of_loss_function.round(4)},{best_analitical_loss_function.round(4)})\n",
    "elif a < b:\n",
    "    print({best_values_of_loss_function.round(4)},{best_analitical_loss_function.round(4)})\n",
    "else:\n",
    "    print({best_values_of_loss_function.round(4)},{best_values_of_loss_function.round(4)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
